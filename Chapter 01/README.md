# Chapter 1 : 아파치 스파크란

### 아파치 스파크

- 통합 컴퓨팅 엔진. 클러스터 환경에서 데이터를 병렬로 처리.
- 스파크 기능 구성
[출처] ([https://gunju-ko.github.io/hadoop/spark/2020/10/07/스파크-기능-둘러보기.html](https://gunju-ko.github.io/hadoop/spark/2020/10/07/%EC%8A%A4%ED%8C%8C%ED%81%AC-%EA%B8%B0%EB%8A%A5-%EB%91%98%EB%9F%AC%EB%B3%B4%EA%B8%B0.html)

![chap1-1](https://user-images.githubusercontent.com/70019911/127878793-9e3435ea-b02d-4027-9d6d-eb46f41162ca.png)

### 아파치 스파크의 철학

1. 통합 - 다양한 데이터 분석 작업을 같은 엔진, 일관성 있는 API로 수행.
2. 컴퓨팅 엔진 - 기능의 범위를 컴퓨팅 엔진으로 제한, 영구 저장소 지원하지 않음. 연산 기능 초점.
3. 라이브러리 - 표준 라이브러리 + 오픈소스 외부 라이브러리
